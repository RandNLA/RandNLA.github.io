<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/tufte.css"> <link rel=stylesheet  href="/css/latex.css"> <link rel=stylesheet  href="/css/adjust.css"> <link rel=stylesheet  href="/css/FranklinTheorems.css"> <link rel=stylesheet  href="/css/algorithm.css"> <link rel=icon  href="/assets/favicon.png"> <title>RandNLA Proof Wiki</title> <div id=layout > <div id=menu > <ul> <li><a href="/">Home</a> </ul> </div> <div id=main > <div class=franklin-content > <h1 id=basic_properties_of_leverage_scores ><a href="#basic_properties_of_leverage_scores" class=header-anchor >Basic Properties of Leverage Scores</a></h1> <p>On this page, we will show that three different definitions of Leverage Scores are equivalent. As a small supplement, we also use two of these forms to bound the maximum value of a leverage score, and also to compute the sum of all leverage scores.</p> <div class=theorem > <h2 class=theorem-header  id=max-char > <a href="#max-char"> Definition 1: Max Characterization</a> <div class=theorem-type > Definition</div> </h2> <div class=theorem-content > Let \(\boldsymbol{A}\in\mathbb{R}^{n \times d}\). Then the Maximum Characterization of the Leverage Score for row \(i\) of \(\boldsymbol{A}\) is</p> \[ \tau_i(\boldsymbol{A}) \;{\vcentcolon=}\; \max_{\mathbf{x}\in\mathbb{R}^d} \frac{[\boldsymbol{A}\mathbf{x}]_i^2}{\|\boldsymbol{A}\mathbf{x}\|_2^2} \] <p></div></div> <hr /> <div class=theorem > <h2 class=theorem-header  id=inner-product-char > <a href="#inner-product-char"> Lemma 1: Inner Product Characterization</a> <div class=theorem-type > Lemma</div> </h2> <div class=theorem-content > Let \(\mathbf{a}_i\) be the \(i^{th}\) row of \(\boldsymbol{A}\). Then,</p> \[ \tau_i(\boldsymbol{A}) = \mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i \] <p></div></div> <button class=theorem-accordion ><div class=theorem-accordion-text > <em>Proof</em> </div></button><div class=theorem-panel ><p> <div class=proof-box ><p><em><strong>Proof.</strong></em> This is proven in two steps. First, we show that the inner product characterization upper bounds the max characterization. Then, we show a matching lower bound. For simplicity, we prove this for full-rank \(\boldsymbol{A}\).</p> <p>Before getting started, we note a useful equation: \[\begin{aligned} \|\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\|_2^2 &= (\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\boldsymbol{A}^\intercal\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i) \\ &= (\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i) \end{aligned}\]</p> <p><em>Upper Bound:</em> To create the upper bound, we relate \[\begin{aligned} [\boldsymbol{A}\mathbf{x}]_i^2 &= (\mathbf{a}_i^\intercal\mathbf{x})^2 \\ &= (\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}(\boldsymbol{A}^\intercal\boldsymbol{A})\mathbf{x})^2 \\ &= ((\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i)^\intercal ~ (\boldsymbol{A}\mathbf{x}))^2 \\ &\leq \|\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\|_2^2 \cdot \|\boldsymbol{A}\mathbf{x}\|_2^2 \\ &= (\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i) \cdot \|\boldsymbol{A}\mathbf{x}\|_2^2 \end{aligned}\] Where the inequality used is the Cauchy-Schwarz Inequality: \((\mathbf{v}^\intercal\mathbf{y})^2\leq \|\mathbf{v}\|_2^2 \cdot \|\mathbf{y}\|_2^2\). We can then give an upper bound to the max characterization:</p> \[ \tau_i(\boldsymbol{A}) = \max_{\mathbf{x}\in\mathbb{R}^d} \frac{[\boldsymbol{A}\mathbf{x}]_i^2}{\|\boldsymbol{A}\|_2^2} \leq \max_{\mathbf{x}\in\mathbb{R}^d} \frac{(\mathbf{a}_i(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i) \cdot \|\boldsymbol{A}\mathbf{x}\|_2^2}{\|\boldsymbol{A}\mathbf{x}\|_2^2} = \mathbf{a}_i(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i \] <p><em>Lower Bound:</em> For the lower bound, we just plug \(\mathbf{x}=(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\) into the max characterization: \[\begin{aligned} \tau_i(\boldsymbol{A}) \geq \frac{[\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i]_i^2}{\|\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\|_2^2} = \frac{(\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i)^2}{\mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i} = \mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i \end{aligned}\] Which completes the proof. <div style="text-align:right"> \(\blacksquare \, \, \) </div></p></div> </p></div> <hr /> <div class=theorem > <h2 class=theorem-header  id=min-char > <a href="#min-char"> Lemma 2: Minimum Characterization</a> <div class=theorem-type > Lemma</div> </h2> <div class=theorem-content > Let \(\mathbf{a}_i\) be the \(i^{th}\) row of \(\boldsymbol{A}\). Then</p> \[ \tau_i(\boldsymbol{A}) = \min_{\mathbf{y}\in\mathbb{R}^n,\,\boldsymbol{A}^\intercal\mathbf{y}=\mathbf{a}_i} \|\mathbf{y}\|_2^2 \] <p></div></div> <button class=theorem-accordion ><div class=theorem-accordion-text > <em>Proof</em> </div></button><div class=theorem-panel ><p> <div class=proof-box ><p><em><strong>Proof.</strong></em> For simplicity, we assume that \(\boldsymbol{A}\) is both full-rank and tall-and-skinny.</p> <p>Notice this minimization problem a minimum-norm underdetermined least-squares problem, with known solution \(\mathbf{y}=\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\). So, we know that</p> \[ \min_{\mathbf{y}\in\mathbb{R}^n,\,\boldsymbol{A}^\intercal\mathbf{y}=\mathbf{a}_i} \|\mathbf{y}\|_2^2 = \|\boldsymbol{A}(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i\|_2^2 = \mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i = \tau_i(\boldsymbol{A}) \] <p>where the second equality is shown in the start to the proof of <span class=bibref ><a href="#inner-product-char">Lemma 1</a></span>, and the last equality is <span class=bibref ><a href="#inner-product-char">Lemma 1</a></span>. <div style="text-align:right"> \(\blacksquare \, \, \) </div></p></div> </p></div> <hr /> <div class=theorem > <h2 class=theorem-header  id=basic-props > <a href="#basic-props"> Lemma 3: Basic Properties of \(\tau_i(\boldsymbol{A})\)</a> <div class=theorem-type > Lemma</div> </h2> <div class=theorem-content > Let \(\boldsymbol{A}\in\mathbb{R}^{n \times d}\) full-rank with \(n \geq d\). Then,</p> <ol> <li><p>Each leverage score has \(\tau_i(\boldsymbol{A})\in[0,1]\)</p> <li><p>If \(\boldsymbol{B}\in\mathbb{R}^{d \times d}\) is full-rank, then \(\tau_i(\boldsymbol{A}\boldsymbol{B}) = \tau_i(\boldsymbol{A})\)</p> <li><p>If \(\boldsymbol{A}^\intercal\boldsymbol{A}=\boldsymbol{I}\), then \(\tau_i(\boldsymbol{A})=\|\mathbf{a}_i\|_2^2\)</p> <li><p>If \(\boldsymbol{U}\in\mathbb{R}^{n \times d}\) with \(\boldsymbol{U}^\intercal\boldsymbol{U}=\boldsymbol{I}\) has the same columnspace as \(\boldsymbol{A}\), then \(\tau_i(\boldsymbol{A})=\|\mathbf{u}_i\|_2^2\) where \(\mathbf{u}_i\) is the \(i^{th}\) row of \(\boldsymbol{U}\).</p> <li><p>The sum of leverages is \(\sum_{i=1}^n \tau_i(\boldsymbol{A})=d\)</p> </ol> <p></div></div> <button class=theorem-accordion ><div class=theorem-accordion-text > <em>Proof</em> </div></button><div class=theorem-panel ><p> <div class=proof-box ><p><em><strong>Proof.</strong></em></p> <p>Point 1 follows directly from the Max Characterization &#40;<span class=bibref ><a href="#max-char">Definition 1</a></span>&#41;.</p> <p>Point 2 also follows form the Max Characterization. In particular, for any \(\mathbf{x}\in\mathbb{R}^{d}\) we can define \(\mathbf{y}\;{\vcentcolon=}\;\boldsymbol{B}\mathbf{x}\). Since \(\boldsymbol{B}\) is invertible, the maximizing over all \(\mathbf{x}\in\mathbb{R}^d\) is equivalent to maximizing over all \(\mathbf{y}\in\mathbb{R}^d\):</p> \[ \tau_i(\boldsymbol{A}\boldsymbol{B}) = \max_{\mathbf{x}\in\mathbb{R}^d} \frac{[\boldsymbol{A}\boldsymbol{B}\mathbf{x}]_i^2}{\|\boldsymbol{A}\boldsymbol{B}\mathbf{x}\|_2^2} = \max_{\mathbf{y}\in\mathbb{R}^d} \frac{[\boldsymbol{A}\mathbf{y}]_i^2}{\|\boldsymbol{A}\mathbf{y}\|_2^2} = \tau_i(\boldsymbol{A}) \] <p>Point 3 follows from the Inner Product Characterization:</p> \[ \tau_i(\boldsymbol{A}) = \mathbf{a}_i^\intercal(\boldsymbol{A}^\intercal\boldsymbol{A})^{-1}\mathbf{a}_i = \mathbf{a}_i^\intercal\mathbf{a}_i = \|\mathbf{a}_i\|_2^2 \] <p>Point 4 follows from Points 2 and 3.</p> <p>Point 5 follows from Point 4: Since every \(\boldsymbol{A}\) has an SVD \(\boldsymbol{A}=\boldsymbol{U}\mSigma\boldsymbol{V}^\intercal\), we can find an orthogonal \(\boldsymbol{U}\) that satisfied Point 4. Let \(\mathbf{u}_i\) denote the \(i^{th}\) row of \(\boldsymbol{U}\) and let \(\hat{\mathbf{u}}_j\) denote the \(j^{th}\) column of \(\boldsymbol{U}\). Then,</p> \[ \sum_{i=1}^n \tau_i(\boldsymbol{A}) = \sum_{i=1}^n \|\mathbf{u}_i\|_2^2 = \sum_{i=1}^n \sum_{j=1}^d \boldsymbol{U}_{ij}^2 = \sum_{j=1}^d \|\hat{\mathbf{u}}_j\|_2^2 = d \] <div style="text-align:right"> \(\blacksquare \, \, \) </div></div> </p></div> <p>There are some intuitive implications from these bullet points:</p> <ul> <li><p>The leverage scores of \(\boldsymbol{A}\) depend <em>only</em> on the range of \(\boldsymbol{A}\). Any other matrix with the same column space has the same leverage scores.</p> <li><p>If \(\boldsymbol{A}=\boldsymbol{Q}\boldsymbol{R}\) is the economic QR decomposition of \(\boldsymbol{A}\), and if \(\mathbf{q}_1,\ldots,\mathbf{q}_n\) are the rows of \(\boldsymbol{Q}\), then \(\tau_i(\boldsymbol{A})=\|\mathbf{q}\|_2^2\).</p> </ul> <h1 id=see_also ><a href="#see_also" class=header-anchor >See Also</a></h1> <p>The proofs above are most closely related to their highly generalized analysis in Theorem 5 from <span class=bibref ><a href="#avron2019universal">Avron et al. (2019)</a></span>.</p> <p>There are many extensions of leverage scores in the literature:</p> <ul> <li><p><span class=bibref >(<a href="#avron2011input">Cohen Musco² (2017)</a>)</span> Ridge Leverage Scores, which relate to Ridge Regression.</p> <li><p><span class=bibref >(<a href="#alaoui2014fast">Alaoui Mahoney (2015)</a>)</span> Kernel Ridge Leverage Scores, which relate to Kernel Ridge Regression.</p> <li><p><span class=bibref >(<a href="#avron2011randomized">Avron et al. (2017)</a>)</span> Kernel Ridge Leverage Function, which relates to Random Fourier Features for Kernel Ridge Regression.</p> <li><p><span class=bibref >(<a href="#chen2019active">Chen Price (2019)</a>)</span> Leverage Function, which relates to Linear Operators instead of matrices. Sometimes called a <em>Sensitvitiy Score</em>.</p> <li><p><span class=bibref >(<a href="#avron2019universal">Avron et al. (2019)</a>)</span> Ridge Leverage Function, which relates to Linear Operators instead of matrices for Ridge Regression .</p> <li><p><span class=bibref >(<a href="#cohen2015lp">Cohen Peng (2019)</a>)</span> Lewis Weights, which relate to \(L_p\) norms instead of just \(L_2\) norms.</p> <li><p><em>Let me know if anything is missing</em></p> </ul> <h1 id=bibliography ><a href="#bibliography" class=header-anchor >Bibliography</a></h1> <ul> <li><p><a id=avron2019universal  class=anchor ></a><strong>Avron</strong>, <strong>Kapralov</strong>, <strong>Musco</strong>, <strong>Musco</strong>, <strong>Velingker</strong>, and <strong>Zandieh</strong>. <a href="https://arxiv.org/pdf/1812.08723.pdf">A Universal Sampling Method for Reconstructing Signals with Simple Fourier Transforms</a>. <em>STOC</em> 2019.</p> <li><p><a id=alaoui2014fast  class=anchor ></a><strong>Alaoui</strong> and <strong>Mahoney</strong>. <a href="https://www.stat.berkeley.edu/~mmahoney/pubs/elalaoui-nips15.pdf">Fast Randomized Kernel Methods with Statistical Guarantees.</a>. <em>NIPS</em> 2015.</p> <li><p><a id=avron2011randomized  class=anchor ></a><strong>Avron</strong>, <strong>Kapralov</strong>, <strong>Musco</strong>, <strong>Musco</strong>, <strong>Velingker</strong>, and <strong>Zandieh</strong>. <a href="https://arxiv.org/pdf/1804.09893.pdf">Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees</a>. <em>ICML</em> 2017.</p> <li><p><a id=avron2011input  class=anchor ></a><strong>Cohen</strong>, <strong>Kapralov</strong>, <strong>Musco</strong>, and <strong>Musco</strong>. <a href="https://arxiv.org/pdf/1511.07263.pdf">Input Sparsity Time Low-Rank Approximation via Ridge Leverage Score Sampling</a>. <em>SODA</em> 2017.</p> <li><p><a id=chen2019active  class=anchor ></a><strong>Chen</strong> and <strong>Price</strong>. <a href="https://arxiv.org/pdf/1511.07263.pdf">Active Regression via Linear-Sample Sparsification</a>. <em>COLT</em> 2019.</p> <li><p><a id=cohen2015lp  class=anchor ></a><strong>Cohen</strong> and <strong>Peng</strong>. <a href="https://arxiv.org/pdf/1412.0588.pdf">\(\ell_p\) Row Sampling by Lewis Weights</a>. <em>STOC</em> 2015.</p> </ul> <script> var acc = document.getElementsByClassName("theorem-accordion"); var i; for (i = 0; i < acc.length; i++) { acc[i].addEventListener("click", function() { this.classList.toggle("active"); var panel = this.nextElementSibling; if (panel.style.maxHeight) { panel.style.maxHeight = null; } else { panel.style.maxHeight = panel.scrollHeight + "px"; } }); } </script> <div class=page-foot > <div class=copyright > &copy; Septimia Zenobia. Last modified: December 06, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> </div> </div> <script src="/libs/katex/katex.min.js"></script> <script src="/libs/katex/auto-render.min.js"></script> <script>renderMathInElement(document.body)</script>